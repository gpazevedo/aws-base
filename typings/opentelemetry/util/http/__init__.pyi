"""
This type stub file was generated by pyright.
"""

from collections.abc import Mapping
from os import environ
from re import IGNORECASE as RE_IGNORECASE, compile as re_compile, search
from typing import Callable, Iterable, overload
from urllib.parse import parse_qs, urlencode, urlparse, urlunparse
from opentelemetry.semconv._incubating.attributes.http_attributes import HTTP_FLAVOR, HTTP_HOST, HTTP_METHOD, HTTP_SCHEME, HTTP_SERVER_NAME, HTTP_STATUS_CODE
from opentelemetry.semconv._incubating.attributes.net_attributes import NET_HOST_NAME, NET_HOST_PORT

OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SANITIZE_FIELDS = ...
OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_REQUEST = ...
OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_RESPONSE = ...
OTEL_PYTHON_INSTRUMENTATION_HTTP_CAPTURE_ALL_METHODS = ...
_duration_attrs = ...
_active_requests_count_attrs = ...
PARAMS_TO_REDACT = ...
class ExcludeList:
    """Class to exclude certain paths (given as a list of regexes) from tracing requests"""
    def __init__(self, excluded_urls: Iterable[str]) -> None:
        ...
    
    def url_disabled(self, url: str) -> bool:
        ...
    


class SanitizeValue:
    """Class to sanitize (remove sensitive data from) certain headers (given as a list of regexes)"""
    def __init__(self, sanitized_fields: Iterable[str]) -> None:
        ...
    
    def sanitize_header_value(self, header: str, value: str) -> str:
        ...
    
    def sanitize_header_values(self, headers: Mapping[str, str | list[str]], header_regexes: list[str], normalize_function: Callable[[str], str]) -> dict[str, list[str]]:
        ...
    


_root = ...
def get_traced_request_attrs(instrumentation: str) -> list[str]:
    ...

def get_excluded_urls(instrumentation: str) -> ExcludeList:
    ...

def parse_excluded_urls(excluded_urls: str) -> ExcludeList:
    """
    Small helper to put an arbitrary url list inside an ExcludeList
    """
    ...

def remove_url_credentials(url: str) -> str:
    """Given a string url, replace the username and password with the keyword `REDACTED` only if it is a valid url"""
    ...

def normalise_request_header_name(header: str) -> str:
    ...

def normalise_response_header_name(header: str) -> str:
    ...

@overload
def sanitize_method(method: str) -> str:
    ...

@overload
def sanitize_method(method: None) -> None:
    ...

def sanitize_method(method: str | None) -> str | None:
    ...

def get_custom_headers(env_var: str) -> list[str]:
    ...

def redact_query_parameters(url: str) -> str:
    """Given a string url, redact sensitive query parameter values"""
    ...

def redact_url(url: str) -> str:
    """Redact sensitive data from the URL, including credentials and query parameters."""
    ...

